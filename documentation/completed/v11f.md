# V11F ‚Äî Agent Tooltips & Upload Status Detail

> **Created:** 2026-02-17
> **Last audited:** 2026-02-17
> **Status:** ‚¨ú Not Started
> **Goal:** Improve agent visibility in the API bar and surface granular upload
> progress with timestamps and backend labels.

---

## Requirements (Original)

1. When you click on the agents in the API bar, you ought to be able to view a popup tooltip showing the agents details. What tools it is connected to, what its prompt is, and what other agents it connects to, if any
2. Scenario uploads - Should show start timestamp, elapsed time, and note if cosmos or fabric backend. More detail like provisioning eventhouse, creating table, etc if at all possible to acquire

> **Note:** Requirement 3 (scenario backend isolation / cross-backend overwrite prevention) was moved to v11e3.md Item 7.
---

## Implementation Status

| Phase | Status | Scope |
|-------|--------|-------|
| **Phase 1:** Agent tooltip enhancement | ‚¨ú Not started | `AgentCard.tsx`, `agent_ids.py`, `agents.py` |
| **Phase 2:** Streaming upload detail + status enrichment | ‚¨ú Not started | `upload_jobs.py`, `ScenarioStatusPanel.tsx` |

### Deviations From Plan

| # | Plan Said | What Was Done | Rationale |
|---|-----------|---------------|-----------|
| D-1 | ‚Äî | ‚Äî | ‚Äî |

### Extra Work Not In Plan

- {None yet}

---

## Table of Contents

- [Requirements (Original)](#requirements-original)
- [Codebase Conventions & Context](#codebase-conventions--context)
- [Overview of Changes](#overview-of-changes)
- [Item 1: Agent Tooltip Enhancement](#item-1-agent-tooltip-enhancement)
- [Item 2: Upload Status Detail & Timestamps](#item-2-upload-status-detail--timestamps)
- [Implementation Phases](#implementation-phases)
- [File Change Inventory](#file-change-inventory)
- [Edge Cases & Validation](#edge-cases--validation)
- [Migration & Backwards Compatibility](#migration--backwards-compatibility)

---

## Codebase Conventions & Context

### Request Routing

| URL prefix | Proxied to | Config |
|------------|-----------|--------|
| `/api/*` | api service (port 8000) | `nginx.conf` L12-17 |
| `/query/*` | graph-query-api service (port 8100) | `nginx.conf` L19-24 |

### Agent Data Flow

```
scenario.yaml (agents section)
  ‚Üí provisioning writes agent_ids.json
  ‚Üí GET /api/agents reads agent_ids.json via agent_ids.py
  ‚Üí AgentBar.tsx ‚Üí AgentCard.tsx
```

Fields available in `agent_ids.json` but **not** currently sent to frontend:
- `instructions_file` ‚Äî path to prompt file(s)
- `compose_with_connector` ‚Äî whether the prompt is composed with connector info

The **prompt text itself** is on disk at `data/scenarios/{name}/prompts/...` ‚Äî NOT in any JSON or API response today.

### Upload Job Data Flow

```
Frontend POST /api/upload-jobs (multipart)
  ‚Üí upload_jobs.py creates job doc, starts asyncio task
  ‚Üí _run_upload_job() calls upload endpoints via httpx (non-streaming)
  ‚Üí SSE responses contain rich progress events but are parsed only for final result
  ‚Üí ScenarioStatusPanel polls GET /api/upload-jobs every 5s
```

### SSE Event Format (All Upload Endpoints)

All `graph-query-api` upload handlers use `SSEProgress`:
```
event: progress
data: {"step": "<label>", "detail": "<text>", "pct": <int>}

event: complete
data: {<result dict>}

event: error
data: {"error": "<message>"}
```

Fabric `provision_graph_from_tarball` uses same format via `_sse_event()`.

### Scenario Identity

- Scenario `id` = scenario `name` (plain string, e.g. `"telco-noc"`)
- Document stored in `scenarios/scenarios` container with `partition_key = /id`
- `graph_connector` field exists (`"cosmosdb-gremlin"` or `"fabric-gql"`) but is NOT part of the unique key
- An upsert with same name but different backend silently overwrites

### Tooltip CSS Pattern

Existing pattern in `AgentCard.tsx`:
```tsx
<div className="absolute left-0 top-full mt-1 z-50 min-w-[220px]
                bg-neutral-bg3 border border-white/10 rounded-lg
                shadow-xl p-3 text-xs text-text-secondary">
```

---

## Overview of Changes

| # | Item | Category | Impact | Effort |
|---|------|----------|--------|--------|
| 1 | Agent tooltip: click-to-open, show prompt, tools, connections | Frontend + Backend | Medium ‚Äî improves agent discoverability | Medium |
| 2 | Upload status: streaming detail, timestamps, backend label | Full-stack | High ‚Äî transforms upload from black-box to observable | Medium |

### Dependency Graph

```
Phase 1 (Agent tooltips)     ‚Äî independent
Phase 2 (Upload detail)      ‚Äî independent
```

Both phases are independent and can be implemented in parallel.

---

## Item 1: Agent Tooltip Enhancement

### Current State

**`AgentCard.tsx`** renders a hover tooltip on `onMouseEnter`/`onMouseLeave`. The tooltip shows:
- Name, Role, Model
- Tools list (type + spec_template)
- Connected agents

**What's missing:**
- **No system prompt** ‚Äî the `instructions_file` field exists in scenario config but is not sent to the frontend. The prompt text itself is on disk, never exposed via API.
- **Click-to-open** ‚Äî current tooltip is hover-only and disappears instantly on mouse exit, making it hard to read long content.

**Problem:** Users can't see agent prompts or understand agent capabilities beyond a brief hover glance.

### Target State

**Click-to-open popover** (not hover tooltip) showing:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  GraphExplorerAgent                              ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
‚îÇ  Role: graph_explorer    Model: gpt-4.1          ‚îÇ
‚îÇ  Status: ‚óè provisioned                           ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  üîß Tools                                        ‚îÇ
‚îÇ  ‚Ä¢ OpenAPI: graph (/query/graph)                 ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  üîó Delegates To                                  ‚îÇ
‚îÇ  ‚Ä¢ TelemetryAgent, RunbookAgent                  ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  üìù System Prompt                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ You are a graph exploration agent. Your    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ role is to query the network topology...   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ [scrollable, max-h-48, monospace]          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Backend Changes

#### `api/app/agent_ids.py` ‚Äî Add `instructions_file` to agent stub

```python
# Current:
agent = {
    "id": entry["id"],
    "name": entry.get("name", role),
    "role": role,
    "model": entry.get("model", ""),
    "status": "provisioned",
}

# New: also include instructions_file
if entry.get("instructions_file"):
    agent["instructions_file"] = entry["instructions_file"]
```

#### `api/app/routers/agents.py` ‚Äî New endpoint: `GET /api/agents/{agent_id}/prompt`

```python
@router.get("/agents/{agent_id}/prompt")
async def get_agent_prompt(agent_id: str):
    """Return the system prompt text for a specific agent."""
    agents = get_agent_list()
    agent = next((a for a in agents if a["id"] == agent_id), None)
    if not agent:
        raise HTTPException(404, "Agent not found")
    
    instructions_file = agent.get("instructions_file")
    if not instructions_file:
        return {"prompt": None, "source": None}
    
    # Resolve prompt path relative to active scenario data dir
    prompt_path = _resolve_prompt_path(instructions_file)
    if not prompt_path or not prompt_path.exists():
        return {"prompt": None, "source": str(instructions_file)}
    
    if prompt_path.is_dir():
        # Composed prompts ‚Äî concatenate all .md files
        parts = sorted(prompt_path.glob("*.md"))
        text = "\n\n---\n\n".join(p.read_text() for p in parts)
    else:
        text = prompt_path.read_text()
    
    return {"prompt": text, "source": str(instructions_file)}
```

> **‚ö†Ô∏è Implementation note:** `_resolve_prompt_path()` needs to find the active scenario's data directory. The active scenario is set via `active_scenario` in config. Check how `config.py` resolves `SCENARIO_DIR` ‚Äî use the same mechanism.

#### `agent_ids.json` ‚Äî Already contains `instructions_file` from provisioning

The provisioning step writes `instructions_file` per agent into `agent_ids.json`. Verify this by examining an existing file ‚Äî if it's missing, add it to the provisioning code in `fabric_provision.py` `_write_agent_ids()`.

### Frontend Changes

#### `AgentCard.tsx` ‚Äî Click-to-open popover with lazy-loaded prompt

```tsx
// Change: hover‚Üíclick toggle, add prompt section
const [isOpen, setIsOpen] = useState(false);
const [prompt, setPrompt] = useState<string | null>(null);
const [loadingPrompt, setLoadingPrompt] = useState(false);

// Lazy-load prompt on first open
useEffect(() => {
  if (isOpen && prompt === null && agent.instructions_file) {
    setLoadingPrompt(true);
    fetch(`/api/agents/${agent.id}/prompt`)
      .then(r => r.json())
      .then(d => setPrompt(d.prompt || '(no prompt found)'))
      .catch(() => setPrompt('(failed to load)'))
      .finally(() => setLoadingPrompt(false));
  }
}, [isOpen, prompt, agent.id, agent.instructions_file]);
```

Popover body addition (after existing tools/connections):
```tsx
{/* System Prompt */}
{agent.instructions_file && (
  <div className="mt-2 pt-2 border-t border-white/5">
    <span className="text-text-muted text-[10px] uppercase tracking-wider">System Prompt</span>
    {loadingPrompt ? (
      <p className="text-[10px] text-text-muted mt-1 animate-pulse">Loading‚Ä¶</p>
    ) : prompt ? (
      <pre className="mt-1 p-2 bg-neutral-bg1 rounded text-[10px] text-text-secondary
                      font-mono whitespace-pre-wrap max-h-48 overflow-y-auto">
        {prompt}
      </pre>
    ) : null}
  </div>
)}
```

> **‚ö†Ô∏è Implementation note:** Change trigger from `onMouseEnter`/`onMouseLeave` to `onClick` toggle. Add click-outside dismiss. Keep the hover dot color behavior.

#### `AgentBar.tsx` ‚Äî Pass `instructions_file` through

Add `instructions_file?: string` to the `AgentData` interface so it's available in `AgentCard`.

### UX Enhancements

#### 1a. Click-Outside Dismiss

**Problem:** Click-to-open popover needs a way to close.

**Fix:** Add `useClickOutside` hook (already exists in the codebase, used by `ScenarioStatusPanel`). Wrap the popover in a ref, call `useClickOutside(ref, () => setIsOpen(false), isOpen)`.

#### 1b. Escape Key Close

**Fix:** Add `useEffect` with keydown listener for Escape when `isOpen === true`.

#### 1c. Tool Path Display

**Problem:** Tools currently show `OpenAPI: graph` which is unclear.

**Fix:** Also show `keep_path` if available ‚Äî display as `OpenAPI: graph ‚Üí /query/graph`.

---

## Item 2: Upload Status Detail & Timestamps

### Current State

**`upload_jobs.py` `_run_upload_job()`** uses non-streaming `httpx.post()`:
- Calls `_update_step(job, step_name, "running", "Uploading‚Ä¶")` once before the HTTP call
- Waits for the full response
- Parses `resp.text` for the final result only
- All intermediate SSE events (e.g. "Creating container 'alerts'...", "Preparing Lakehouse‚Ä¶") are **discarded**

**`ScenarioStatusPanel.tsx`** shows:
- Scenario name + overall status
- Per-step: name + status icon + `step.detail` (truncated)
- **Missing:** start timestamp, elapsed time, backend label

**The SSE events already contain rich detail strings.** Every upload endpoint emits
events like `"Creating container 'telco-noc-AlertStream'‚Ä¶"`, `"Loading delta tables‚Ä¶"`,
`"Building ontology definition‚Ä¶"`. They're just not being captured.

**Available SSE detail strings by step type:**

| Step | Example detail strings emitted |
|------|-------------------------------|
| **graph** (Cosmos) | `"Preparing graph data from schema..."`, `"Prepared 42 vertices, 80 edges"`, `"Loading vertices batch 3/10"` |
| **graph** (Fabric) | `"Preparing Lakehouse‚Ä¶"`, `"Lakehouse ready: <id>"`, `"Uploading CSVs to Lakehouse‚Ä¶"`, `"Loading delta tables‚Ä¶"`, `"Creating ontology‚Ä¶"`, `"Building ontology definition‚Ä¶"`, `"Discovering graph model‚Ä¶"` |
| **telemetry** | `"Creating container 'telco-noc-AlertStream'‚Ä¶"`, `"Upserting 150 docs into AlertStream‚Ä¶"`, `"‚úì AlertStream: 150 docs"` |
| **runbooks** | `"Found 12 runbook files"`, `"Creating search index 'telco-noc-runbooks-index'‚Ä¶"` |
| **tickets** | Same pattern as runbooks |
| **prompts** | `"Found 6 .md files"`, `"Stored orchestrator: orchestrator.md (v1)"`, `"Stored graph_explorer (composed)"` |

**Problem:** Upload jobs are a black box ‚Äî users see "Uploading‚Ä¶" for minutes with no detail, no timestamps, and no indication of which backend is being used.

### Target State

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  telco-noc                     ‚ü≥ 45%  ‚è± 2m 31s         ‚îÇ
‚îÇ  ‚óÜ Fabric                     Started 19:03:22          ‚îÇ
‚îÇ  ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë                        ‚îÇ
‚îÇ  ‚îú‚îÄ ‚úì graph         Graph Model: abc123                 ‚îÇ
‚îÇ  ‚îú‚îÄ ‚ü≥ telemetry     Creating container 'AlertStream'‚Ä¶   ‚îÇ  ‚Üê LIVE DETAIL
‚îÇ  ‚îú‚îÄ ‚óã runbooks                                          ‚îÇ
‚îÇ  ‚îú‚îÄ ‚óã tickets                                           ‚îÇ
‚îÇ  ‚îî‚îÄ ‚óã prompts                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Backend Changes

#### `api/app/routers/upload_jobs.py` ‚Äî Switch to streaming SSE parsing

Replace the non-streaming `client.post()` + post-hoc text parsing with `client.stream()` + real-time SSE event parsing:

```python
# Current (non-streaming, discards intermediate events):
with open(file_path, "rb") as f:
    resp = await client.post(endpoint, files={...}, params={...})
if resp.status_code == 200:
    detail = "Done"
    for line in resp.text.split("\n"):
        ...

# New (streaming, captures live progress):
import time

_last_persist_ts: dict[str, float] = {}

async def _throttled_persist(job: dict) -> None:
    """Persist at most once per 2 seconds to avoid Cosmos write storms."""
    now = time.time()
    if now - _last_persist_ts.get(job["id"], 0) >= 2.0:
        _last_persist_ts[job["id"]] = now
        await _persist_job(job)

async def _stream_upload(client, endpoint, *, files_data, extra_data=None,
                         params=None, job, step_name, timeout=300):
    """Stream an SSE upload endpoint, updating job step detail in real-time."""
    detail = "Starting‚Ä¶"
    
    req = client.build_request(
        "POST", endpoint,
        files=files_data,
        data=extra_data,
        params=params,
        timeout=timeout,
    )
    async with client.send(req, stream=True) as resp:
        if resp.status_code != 200:
            body = (await resp.aread()).decode()[:200]
            return False, f"HTTP {resp.status_code}: {body}"
        
        buffer = ""
        async for chunk in resp.aiter_text():
            buffer += chunk
            while "\n" in buffer:
                line, buffer = buffer.split("\n", 1)
                line = line.strip()
                if not line.startswith("data: "):
                    continue
                try:
                    data = json.loads(line[6:])
                except Exception:
                    continue
                
                if "error" in data:
                    return False, data["error"]
                
                # Progress event ‚Äî update step detail live
                if "detail" in data:
                    detail = data["detail"]
                    pct = data.get("pct", 0)
                    _update_step(job, step_name, "running", detail, pct)
                    await _throttled_persist(job)
                
                # Complete event
                if any(k in data for k in ("graph", "index", "prompts_stored", "message")):
                    detail = data.get("message", json.dumps(data)[:100])
    
    return True, detail
```

Then refactor `_run_upload_job` to call `_stream_upload()` instead of the inline `client.post()` call:

```python
# In the step loop, replace the entire try block:
ok, result_detail = await _stream_upload(
    client, endpoint,
    files_data=[("file", (file_path.name, open(file_path, "rb"), "application/gzip"))],
    extra_data=extra_data,  # workspace params for Fabric, None for Cosmos
    params={"scenario_name": scenario_name} if not is_fabric else None,
    job=job, step_name=step_name,
    timeout=600 if is_fabric else 300,
)
if ok:
    _update_step(job, step_name, "done", result_detail, 100)
else:
    _update_step(job, step_name, "error", result_detail)
    job["error"] = f"{step_name}: {result_detail}"
```

> **‚ö†Ô∏è Implementation note:** The `open(file_path, "rb")` in the files tuple stays open through the streaming context. httpx handles closing it. But verify file handles are properly cleaned up ‚Äî consider wrapping in a `with` block that spans the `_stream_upload` call.

> **‚ö†Ô∏è Persist throttling:** `_throttled_persist` limits Cosmos writes to 1 per 2 seconds during streaming. The final `_persist_job(job)` after each step (already in the main loop) ensures the final state is always written.

### Frontend Changes

#### `ScenarioStatusPanel.tsx` ‚Äî Add timestamps, elapsed time, backend label

**Update `Job` interface:**
```typescript
interface Job {
  id: string;
  scenario_name: string;
  status: 'pending' | 'running' | 'done' | 'error';
  overall_pct: number;
  created_at: string;
  updated_at?: string;       // NEW
  backend?: string;           // NEW
  workspace_name?: string;    // NEW
  steps: JobStep[];
  error?: string | null;
}
```

**Add helper functions:**
```typescript
function formatElapsed(seconds: number): string {
  const m = Math.floor(seconds / 60);
  const s = seconds % 60;
  return m > 0 ? `${m}m ${s.toString().padStart(2, '0')}s` : `${s}s`;
}

function durationSeconds(start: string, end: string): number {
  return Math.floor((new Date(end).getTime() - new Date(start).getTime()) / 1000);
}

function elapsedFor(job: Job): number {
  return Math.floor((Date.now() - new Date(job.created_at).getTime()) / 1000);
}
```

**Add metadata row below job header:**
```tsx
{/* Metadata row: backend badge + timestamps */}
<div className="flex items-center justify-between text-[10px] text-text-muted">
  <span className={job.backend === 'fabric-gql' ? 'text-cyan-400' : 'text-status-success'}>
    {job.backend === 'fabric-gql' ? '‚óÜ Fabric' : '‚óè Cosmos'}
  </span>
  <span className="flex items-center gap-2">
    <span>Started {new Date(job.created_at).toLocaleTimeString()}</span>
    {(job.status === 'running' || job.status === 'pending') && (
      <span className="font-mono tabular-nums">‚è± {formatElapsed(elapsedFor(job))}</span>
    )}
    {(job.status === 'done' || job.status === 'error') && job.updated_at && (
      <span className="font-mono tabular-nums">
        ‚è± {formatElapsed(durationSeconds(job.created_at, job.updated_at))}
      </span>
    )}
  </span>
</div>
```

> **‚ö†Ô∏è Implementation note:** `elapsedFor()` computes from `Date.now()` ‚Äî it updates every time the component re-renders (every 5s poll). For smoother ticking, add a `setInterval(1000)` when jobs are running (P2 enhancement).

### UX Enhancements

#### 2a. Backend Badge Colors

**Fix:** Fabric gets `text-cyan-400` (cyan), Cosmos gets `text-status-success` (green), matching the `ScenarioChip` badge convention used elsewhere in the app.

#### 2b. Step Detail Max Width

**Problem:** Long detail strings like `"Creating container 'telco-noc-AlertStream-Metrics'‚Ä¶"` may overflow.

**Fix:** Already truncated at `max-w-[140px]`. Consider increasing to `max-w-[180px]` since the panel width is `w-96` (384px) and there's room.

#### 2c. 1-Second Elapsed Timer (P2)

For running jobs, add a `setInterval(1000)` that forces re-render so elapsed time ticks every second instead of every 5s poll cycle. Similar pattern to the timer that was in the old `useScenarioUpload`.

---

## Implementation Phases

### Phase 1: Agent Tooltip Enhancement

> Independent ‚Äî no prerequisites

**Files to modify:**
- `api/app/agent_ids.py` ‚Äî include `instructions_file` in stub (~3 lines)
- `api/app/routers/agents.py` ‚Äî new `GET /api/agents/{agent_id}/prompt` endpoint (~30 lines)
- `frontend/src/components/AgentCard.tsx` ‚Äî click-to-open popover, lazy prompt load (~40 lines delta)
- `frontend/src/components/AgentBar.tsx` ‚Äî add `instructions_file` to `AgentData` interface (~1 line)

**Verification:**
- Click agent pill ‚Üí popover opens with name, role, model, tools, connections
- If agent has `instructions_file`, prompt section appears after lazy load
- Click outside or press Escape ‚Üí popover closes
- Hover still shows status dot color change
- **Verify prompt path resolution** ‚Äî check that `_resolve_prompt_path()` finds the correct file relative to the active scenario directory

### Phase 2: Streaming Upload Detail + Status Enrichment

> Independent ‚Äî no prerequisites

**Files to modify:**
- `api/app/routers/upload_jobs.py` ‚Äî replace non-streaming POST with `client.stream()` + `_stream_upload()` helper, add `_throttled_persist` (~60 lines changed)
- `frontend/src/components/ScenarioStatusPanel.tsx` ‚Äî add `backend`, `updated_at` to Job interface, render timestamps + backend label + live elapsed (~40 lines added)

**Verification:**
- Start a scenario upload
- Open Uploads panel ‚Üí see start timestamp, live elapsed time, backend badge
- **Watch step detail update in real-time** ‚Äî should cycle through detail strings like "Creating container‚Ä¶", "Loading vertices batch 3/10‚Ä¶" on each 5s poll
- After completion, elapsed time shows final duration (updated_at ‚àí created_at)
- Fabric upload shows "‚óÜ Fabric" badge; Cosmos shows "‚óè Cosmos"
- **Verify throttled persist** ‚Äî check graph-query-api logs to confirm Cosmos doc writes don't exceed ~1 per 2 seconds during streaming

---

## File Change Inventory

| File | Action | Phase | Changes |
|------|--------|-------|---------|
| `api/app/agent_ids.py` | MODIFY | 1 | Add `instructions_file` to `_make_agent_stub` (~3 lines) |
| `api/app/routers/agents.py` | MODIFY | 1 | New `GET /api/agents/{agent_id}/prompt` endpoint (~30 lines) |
| `frontend/src/components/AgentCard.tsx` | MODIFY | 1 | Click-to-open popover, lazy prompt fetch, click-outside close (~40 lines) |
| `frontend/src/components/AgentBar.tsx` | MODIFY | 1 | Add `instructions_file` to `AgentData` interface (~1 line) |
| `api/app/routers/upload_jobs.py` | MODIFY | 2 | `_stream_upload()` helper + `_throttled_persist`, refactor step loop (~60 lines) |
| `frontend/src/components/ScenarioStatusPanel.tsx` | MODIFY | 2 | Timestamps, elapsed time, backend label, helpers (~40 lines) |

### Files NOT Changed

- `graph-query-api/sse_helpers.py` ‚Äî SSE event format is already correct; no changes needed
- `graph-query-api/ingest/graph_ingest.py` ‚Äî already emits fine-grained progress events
- `graph-query-api/ingest/telemetry_ingest.py` ‚Äî already emits "Creating container‚Ä¶" events
- `graph-query-api/ingest/knowledge_ingest.py` ‚Äî already emits "Creating search index‚Ä¶" events
- `graph-query-api/ingest/prompt_ingest.py` ‚Äî already emits per-prompt stored events
- `api/app/routers/fabric_provision.py` ‚Äî already emits step-by-step SSE events via `_sse_event()`
- `frontend/src/types/index.ts` ‚Äî `Job` interface is local to `ScenarioStatusPanel`, not global
- `graph-query-api/router_docs.py` ‚Äî upload-jobs Cosmos proxy already works; no changes
- `nginx.conf` ‚Äî no new route prefixes needed

---

## Edge Cases & Validation

### Agent Tooltip (Item 1)

**Agent with no `instructions_file`:** Prompt section is simply not rendered. The `if agent.instructions_file` guard handles this gracefully.

**Composed prompts (directory of .md files):** `instructions_file` points to a directory (e.g. `"prompts/graph_explorer/"`). The endpoint concatenates all `.md` files sorted alphabetically with `---` separators. Verify ordering is deterministic.

**Prompt file not found:** Return `{"prompt": null, "source": "prompts/missing.md"}`. Frontend shows "(prompt file not found)" with the source path for debugging.

**Long prompts (2000+ words):** The `max-h-48 overflow-y-auto` on the `<pre>` element provides scrollable containment. Verify scrolling works.

**Multiple popovers:** Only one should be open at a time. Use click-outside dismiss on each card ‚Äî clicking agent B will close agent A's popover naturally via the click-outside handler, then open B.

### Upload Status (Item 2)

**SSE arriving as partial chunks:** SSE text may arrive split mid-line. The `buffer += chunk; while "\n" in buffer` pattern handles partial reads correctly.

**Throttle edge case:** The final progress event before `complete` might be throttled and not persisted. This is fine ‚Äî the `_persist_job(job)` call after the step completes (already in the main loop) always writes the final state.

**Cosmos proxy unavailable:** `_throttled_persist()` inherits from `_persist_job()` which already has `try/except` with `logger.warning`. Step detail is still updated in the in-memory `_jobs` dict and served on the next poll.

**Clock skew (server vs browser):** `elapsedFor(job)` computes from `Date.now()` vs server `created_at`. If clocks differ significantly, elapsed time may show incorrect values for running jobs. The final duration uses `updated_at - created_at` (both server timestamps) which is always correct.

---

## Migration & Backwards Compatibility

### Existing Data

- **Scenario docs** without `graph_connector` default to `"cosmosdb-gremlin"` ‚Äî matches existing behavior, no migration needed
- **Upload job docs** already have `backend`, `created_at`, `updated_at` fields from v11e2 ‚Äî no schema changes needed
- **`agent_ids.json`** files from before this change won't have `instructions_file` ‚Äî the optional field check (`if entry.get(...)`) handles this gracefully

### API Surface Compatibility

- **New endpoint:** `GET /api/agents/{agent_id}/prompt` ‚Äî purely additive
- **No breaking changes** to existing response shapes; all new fields are optional

### Rollback Plan

- **Phase 1** (agent tooltips): Revert frontend. Backend endpoint is harmless if unused.
- **Phase 2** (upload streaming): Revert `upload_jobs.py` to non-streaming. Jobs still work, just show less detail.

---

## UX Priority Matrix

| Priority | Enhancement | Item | Effort | Impact |
|----------|------------|------|--------|--------|
| **P0** | Streaming step detail in upload jobs | 2 | Medium | High ‚Äî transforms black-box into observable |
| **P0** | Timestamps + elapsed time in status panel | 2 | Small | Medium ‚Äî basic upload observability |
| **P0** | Backend label (Cosmos/Fabric) on jobs | 2 | Tiny | Medium ‚Äî clarifies which pipeline is running |
| **P1** | Click-to-open agent popover (vs hover) | 1 | Small | Medium ‚Äî makes tooltips usable |
| **P1** | Lazy-loaded prompt text in popover | 1 | Small | Medium ‚Äî core of R1 requirement |
| **P1** | Click-outside + Escape dismiss | 1 | Tiny | Medium ‚Äî basic popover UX |
| **P2** | 1-second elapsed timer for running jobs | 2 | Tiny | Low ‚Äî cosmetic smoothness |
| **P2** | Tool path display (‚Üí /query/graph) | 1 | Tiny | Low ‚Äî minor clarity |