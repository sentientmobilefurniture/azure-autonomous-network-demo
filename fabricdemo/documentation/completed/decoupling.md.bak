# Scenario Decoupling — Implementation Plan

> **Goal:** Remove every hardcoded `telco-noc` reference from source code so that `./deploy.sh --scenario <name>` reads everything from `data/scenarios/<name>/scenario.yaml` and provisions automatically.

> **Invariant:** After this work, adding a new scenario requires **only** creating a new `data/scenarios/<name>/` folder with a valid `scenario.yaml` — zero code changes.

---

## 0. Design Principles

| Principle | Rule |
|---|---|
| **Single source of truth** | `scenario.yaml` is the only place scenario-specific values live. |
| **Runtime env var** | `DEFAULT_SCENARIO` is the one env var that names the active scenario. Every consumer reads it. |
| **Resolve-once, pass-down** | A new shared module (`scenario_loader.py`) parses `scenario.yaml` once and hands a typed dict to all consumers. |
| **No search-and-replace** | Don't just swap `telco-noc` for a variable — delete the hardcoded structures entirely and derive them from `scenario.yaml`. |

---

## 1. Add `--scenario` to `deploy.sh`

**File:** `deploy.sh`

### 1.1 New CLI flag

Add a `--scenario` argument alongside the existing flags:

```bash
SCENARIO_NAME=""

while [[ $# -gt 0 ]]; do
  case "$1" in
    --scenario)  SCENARIO_NAME="$2"; shift 2 ;;
    # ... existing flags ...
  esac
done
```

### 1.2 Default discovery

If `--scenario` is not provided, auto-detect. One of:
- Read from `DEFAULT_SCENARIO` env var (if set).
- If exactly one directory exists in `data/scenarios/`, use it.
- If multiple exist, prompt the user (unless `--yes`, in which case fail with a clear message).

```bash
if [[ -z "$SCENARIO_NAME" ]]; then
  SCENARIO_NAME="${DEFAULT_SCENARIO:-}"
fi
if [[ -z "$SCENARIO_NAME" ]]; then
  SCENARIOS=( $(ls -d "$PROJECT_ROOT/data/scenarios"/*/ 2>/dev/null | xargs -I{} basename {}) )
  if (( ${#SCENARIOS[@]} == 1 )); then
    SCENARIO_NAME="${SCENARIOS[0]}"
  elif (( ${#SCENARIOS[@]} > 1 )); then
    if $AUTO_YES; then
      fail "Multiple scenarios found. Pass --scenario <name>."
      exit 1
    fi
    choose "Which scenario?" "${SCENARIOS[@]}"
    SCENARIO_NAME="$CHOSEN"
  else
    fail "No scenarios found in data/scenarios/"
    exit 1
  fi
fi
```

### 1.3 Validate and export

```bash
SCENARIO_DIR="$PROJECT_ROOT/data/scenarios/$SCENARIO_NAME"
SCENARIO_YAML="$SCENARIO_DIR/scenario.yaml"

if [[ ! -f "$SCENARIO_YAML" ]]; then
  fail "Scenario manifest not found: $SCENARIO_YAML"
  exit 1
fi

export DEFAULT_SCENARIO="$SCENARIO_NAME"
info "Scenario: $SCENARIO_NAME (from $SCENARIO_YAML)"
```

### 1.4 Propagate to azd env

```bash
azd env set DEFAULT_SCENARIO "$SCENARIO_NAME"
```

This ensures `DEFAULT_SCENARIO` is available in `postprovision.sh` hooks, Container App env vars, and all downstream scripts.

### 1.5 Pass scenario to topology generation (Step 2b)

Replace the hardcoded invocation:

```bash
# Before
(cd "$PROJECT_ROOT" && uv run python "$TOPO_SCRIPT")

# After
(cd "$PROJECT_ROOT" && uv run python "$TOPO_SCRIPT" --scenario "$SCENARIO_NAME")
```

`generate_topology_json.py` already accepts `--scenario` — this just wires it up.

### 1.6 Pass scenario to provisioning steps (Steps 5–7)

Each provisioning script already reads `DEFAULT_SCENARIO` from env. Since we exported it in 1.3, no changes needed to the invocation lines — but we must ensure each script actually honours it (covered in later steps).

---

## 2. Create `scenario_loader.py` — the shared resolver

**New file:** `scripts/scenario_loader.py`

This is the single module that parses `scenario.yaml` and returns a structured dict. Every script imports from here instead of hardcoding paths or names.

```python
"""
scenario_loader.py — Parse scenario.yaml and return a resolved config dict.

Usage:
    from scenario_loader import load_scenario

    sc = load_scenario()           # uses DEFAULT_SCENARIO env var
    sc = load_scenario("telco-noc")  # explicit name
"""
from __future__ import annotations

import os
import sys
from pathlib import Path

import yaml

PROJECT_ROOT = Path(__file__).resolve().parent.parent


def load_scenario(name: str | None = None) -> dict:
    """Load and validate scenario.yaml, returning a resolved config dict.

    Args:
        name: Scenario folder name. Defaults to DEFAULT_SCENARIO env var.

    Returns:
        Dict with keys:
          name, display_name, description, version, domain,
          scenario_dir (Path), paths (resolved to absolute),
          data_sources, agents, graph_styles, ...

    Raises:
        SystemExit if scenario not found or invalid.
    """
    if name is None:
        name = os.environ.get("DEFAULT_SCENARIO", "")
    if not name:
        print("ERROR: No scenario specified. Set DEFAULT_SCENARIO or pass name explicitly.")
        sys.exit(1)

    scenario_dir = PROJECT_ROOT / "data" / "scenarios" / name
    manifest = scenario_dir / "scenario.yaml"

    if not manifest.exists():
        print(f"ERROR: Scenario manifest not found: {manifest}")
        sys.exit(1)

    with open(manifest) as f:
        cfg = yaml.safe_load(f)

    # Resolve relative paths to absolute
    raw_paths = cfg.get("paths", {})
    resolved_paths = {}
    for key, rel in raw_paths.items():
        resolved_paths[key] = scenario_dir / rel

    cfg["scenario_dir"] = scenario_dir
    cfg["paths"] = resolved_paths

    # Convenience shortcuts for the most common lookups
    ds = cfg.get("data_sources", {})
    graph_cfg = ds.get("graph", {}).get("config", {})
    cfg["graph_name"] = graph_cfg.get("graph", name + "-topology")
    cfg["container_prefix"] = ds.get("telemetry", {}).get("config", {}).get("container_prefix", name)

    search_idx = ds.get("search_indexes", {})
    cfg["runbooks_index_name"] = search_idx.get("runbooks", {}).get("index_name", f"{name}-runbooks-index")
    cfg["tickets_index_name"] = search_idx.get("tickets", {}).get("index_name", f"{name}-tickets-index")
    cfg["runbooks_blob_container"] = search_idx.get("runbooks", {}).get("blob_container", "runbooks")
    cfg["tickets_blob_container"] = search_idx.get("tickets", {}).get("blob_container", "tickets")

    return cfg
```

### 2.1 Why a separate module?

- Scripts (`scripts/*.py`) import it.
- Runtime services (`api/`, `graph-query-api/`) can also import it (or read the same YAML themselves — see steps 4 and 5).
- Keeps YAML parsing + validation in one place.

---

## 3. Update provisioning scripts (`scripts/`)

Each script replaces its hardcoded path / name with a call to `load_scenario()`.

### 3.1 `scripts/provision_search_index.py`

| Line | Before | After |
|---|---|---|
| 8 | Docstring: "For the telco-noc demo" | "For the active scenario" |
| 70 | `KNOWLEDGE_DIR = ... / "scenarios" / "telco-noc" / "data" / "knowledge"` | `sc = load_scenario()` then `KNOWLEDGE_DIR = sc["paths"]["runbooks"].parent` |

Also derive index names from `sc["runbooks_index_name"]` and `sc["tickets_index_name"]` instead of hardcoded `"runbooks-index"` / `"tickets-index"`.

### 3.2 `scripts/provision_cosmos.py`

| Line | Before | After |
|---|---|---|
| 6, 10 | Docstring references "telco-noc" | Generic text |
| 47 | `DATA_DIR = ... / "scenarios" / "telco-noc" / "data" / "telemetry"` | `sc = load_scenario()` then `DATA_DIR = sc["paths"]["telemetry"]` |

Container definitions should also come from `sc["data_sources"]["telemetry"]["config"]["containers"]` rather than being duplicated in the script.

### 3.3 `scripts/provision_agents.py`

| Line | Before | After |
|---|---|---|
| 31 | `SCENARIO = os.environ.get("DEFAULT_SCENARIO", "telco-noc")` | `sc = load_scenario()` |
| 90 | `"graph_name": os.environ.get("DEFAULT_SCENARIO", "telco-noc")` | `"graph_name": sc["graph_name"]` |

`PROMPTS_DIR` becomes `sc["paths"]["prompts"]` (the scenario.yaml `paths.prompts` field).

### 3.4 `scripts/generate_topology_json.py`

| Line | Before | After |
|---|---|---|
| 166 | `default="telco-noc"` (argparse) | `default=os.environ.get("DEFAULT_SCENARIO", "telco-noc")` |

This script already accepts `--scenario` and resolves `data/scenarios/<name>` — just change the default so it falls through to the env var. Minimal change.

### 3.5 `scripts/fabric/provision_lakehouse.py`

| Line | Before | After |
|---|---|---|
| 42 | `SCENARIO = os.environ.get("DEFAULT_SCENARIO", "telco-noc")` | Already reads env var — just remove the `"telco-noc"` fallback and let it fail-fast if missing. Or import `load_scenario()`. |

The actual data dir is already dynamic: `DATA_DIR / "scenarios" / SCENARIO / "data" / "entities"`. The only change is replacing the fallback default.

### 3.6 `scripts/fabric/provision_eventhouse.py`

| Line | Before | After |
|---|---|---|
| 38 | `SCENARIO = os.environ.get("DEFAULT_SCENARIO", "telco-noc")` | Same as 3.5 — remove fallback default. |

### 3.7 `scripts/agent_provisioner.py`

| Line | Before | After |
|---|---|---|
| 146 | Comment: `"telco-noc-topology"` prefix match example | Update comment text |
| 214 | Docstring: graph_name example | Update docstring text |

These are comments/docstrings only — no logic changes, just update the text to be generic or use `<scenario>-topology` placeholder syntax.

---

## 4. Update `graph-query-api/` (runtime service)

The graph-query-api runs inside the container. It needs to read `scenario.yaml` to know graph names, index names, etc.

### 4.1 `graph-query-api/config.py` — replace hardcoded config with YAML loader

**Current state:** `DEFAULT_GRAPH = "telco-noc-topology"`, `DATA_SOURCES` dict hardcoded, `ScenarioContext` class hardcoded.

**Target:** Load these from `scenario.yaml` at startup.

Since `graph-query-api/` is a separate service (different working directory in the container), we need to either:
- **Option A:** Copy `scenario_loader.py` into `graph-query-api/` (duplication, but simple).
- **Option B:** Make `scenario_loader.py` importable from both (symlink or shared package).
- **Option C (recommended):** Add a lightweight YAML reader directly in `graph-query-api/config.py` that reads the same `scenario.yaml` file. The Dockerfile already copies `data/` into the container image.

**Implementation (Option C):**

```python
# graph-query-api/config.py

import yaml

SCENARIO_NAME = os.getenv("DEFAULT_SCENARIO", "")
_SCENARIO_YAML = Path(__file__).resolve().parent.parent / "data" / "scenarios" / SCENARIO_NAME / "scenario.yaml"

def _load_scenario_config() -> dict:
    if not _SCENARIO_YAML.exists():
        logger.warning("scenario.yaml not found at %s — using env var defaults", _SCENARIO_YAML)
        return {}
    with open(_SCENARIO_YAML) as f:
        return yaml.safe_load(f)

_SCENARIO = _load_scenario_config()

# Derived from scenario.yaml instead of hardcoded
DEFAULT_GRAPH = (
    _SCENARIO.get("data_sources", {}).get("graph", {}).get("config", {}).get("graph", f"{SCENARIO_NAME}-topology")
    if _SCENARIO else os.getenv("DEFAULT_GRAPH", "")
)

DATA_SOURCES = {
    "graph": {
        "connector": _SCENARIO.get("data_sources", {}).get("graph", {}).get("connector", "fabric-gql"),
        "resource_name": DEFAULT_GRAPH,
    },
    "telemetry": {
        "connector": _SCENARIO.get("data_sources", {}).get("telemetry", {}).get("connector", "fabric-kql"),
        "resource_name": "NetworkTelemetryEH",
    },
    "search_indexes": {
        "runbooks": {"index_name": _SCENARIO.get("data_sources", {}).get("search_indexes", {}).get("runbooks", {}).get("index_name", "runbooks-index")},
        "tickets": {"index_name": _SCENARIO.get("data_sources", {}).get("search_indexes", {}).get("tickets", {}).get("index_name", "tickets-index")},
    },
}
```

### 4.2 `graph-query-api/router_health.py`

| Line | Before | After |
|---|---|---|
| 2, 4 | Docstring: `"telco-noc"` | Update to generic text |
| 96 | `Query(default="telco-noc")` | `Query(default=SCENARIO_NAME)` — import `SCENARIO_NAME` from config |
| 104 | `"telco-noc-topology"` fallback | `DEFAULT_GRAPH` from config (already imported) |

### 4.3 `graph-query-api/search_indexer.py`

| Lines 82–83 | Before | After |
|---|---|---|
| Docstring examples | `"telco-noc-runbooks-index"`, `"telco-noc-runbooks"` | Replace with generic examples or `<scenario>-runbooks-index` |

These are docstrings only — cosmetic.

### 4.4 `graph-query-api/services/blob_uploader.py`

| Line 31 | Before | After |
|---|---|---|
| Docstring example | `"telco-noc-runbooks"` | Generic example |

Docstring only — cosmetic.

---

## 5. Update `api/app/routers/config.py` (runtime service)

**Current state:** 270-line hardcoded `SCENARIO_CONFIG` dict with agent definitions, data source labels, and a `_build_resource_graph()` call that passes `"telco-noc"`.

**Target:** Load everything from `scenario.yaml`.

### 5.1 Add scenario YAML loader

Same pattern as graph-query-api. The `api/` Dockerfile also copies the full project tree, so `scenario.yaml` is available.

```python
import yaml

SCENARIO_NAME = os.getenv("DEFAULT_SCENARIO", "")
_SCENARIO_YAML = PROJECT_ROOT / "data" / "scenarios" / SCENARIO_NAME / "scenario.yaml"

def _load_scenario_yaml() -> dict:
    if not _SCENARIO_YAML.exists():
        logger.warning("scenario.yaml not found — resource graph will be empty")
        return {}
    with open(_SCENARIO_YAML) as f:
        return yaml.safe_load(f)
```

### 5.2 Build `SCENARIO_CONFIG` from YAML

Replace the entire hardcoded `SCENARIO_CONFIG` dict with a function that generates it from the parsed YAML:

```python
def _build_scenario_config(manifest: dict) -> dict:
    """Convert scenario.yaml into the internal SCENARIO_CONFIG format."""
    agents = []
    for ag in manifest.get("agents", []):
        agents.append({
            "name": ag["name"],
            "model": ag.get("model", "gpt-4.1"),
            "is_orchestrator": ag.get("is_orchestrator", False),
            "tools": ag.get("tools", []),
            "connected_agents": ag.get("connected_agents", []),
        })

    ds = manifest.get("data_sources", {})
    graph_cfg = ds.get("graph", {}).get("config", {})
    search = ds.get("search_indexes", {})

    data_sources = {
        "graph": {
            "type": ds.get("graph", {}).get("connector", "fabric-gql"),
            "label": f"Fabric GQL ({graph_cfg.get('graph', '')})",
            "workspace": os.getenv("FABRIC_WORKSPACE_ID", ""),
            "graph_model": "(auto-discovered at runtime)",
        },
        "telemetry": {
            "type": ds.get("telemetry", {}).get("connector", "fabric-kql"),
            "label": "Fabric KQL (NetworkTelemetryEH)",
            "eventhouse": "(auto-discovered at runtime)",
        },
        "runbooks": {
            "type": "azure_ai_search",
            "label": f"AI Search ({search.get('runbooks', {}).get('index_name', 'runbooks-index')})",
            "index": search.get("runbooks", {}).get("index_name", "runbooks-index"),
        },
        "tickets": {
            "type": "azure_ai_search",
            "label": f"AI Search ({search.get('tickets', {}).get('index_name', 'tickets-index')})",
            "index": search.get("tickets", {}).get("index_name", "tickets-index"),
        },
    }

    return {"agents": agents, "data_sources": data_sources}

_manifest = _load_scenario_yaml()
SCENARIO_CONFIG = _build_scenario_config(_manifest) if _manifest else {"agents": [], "data_sources": {}}
```

### 5.3 Update `_load_current_config()`

Replace `"graph": "telco-noc"` with `"graph": SCENARIO_NAME`.

### 5.4 Update `get_resource_graph` endpoint

Replace `_build_resource_graph(SCENARIO_CONFIG, "telco-noc")` with `_build_resource_graph(SCENARIO_CONFIG, SCENARIO_NAME)`.

---

## 6. Update frontend (`frontend/src/config.ts`)

**Current state:** All values hardcoded in a `SCENARIO` const.

**Target:** Fetch scenario config from the API at runtime.

### 6.1 Add API endpoint for scenario metadata

In `api/app/routers/config.py`, add a new endpoint:

```python
@router.get("/scenario", summary="Get active scenario metadata")
async def get_scenario_metadata():
    """Return scenario name, display name, graph styles, example questions."""
    return {
        "name": SCENARIO_NAME,
        "displayName": _manifest.get("display_name", SCENARIO_NAME),
        "description": _manifest.get("description", ""),
        "graph": _manifest.get("data_sources", {}).get("graph", {}).get("config", {}).get("graph", ""),
        "graphStyles": _build_graph_styles(_manifest),
        "exampleQuestions": _manifest.get("example_questions", []),
        "useCases": _manifest.get("use_cases", []),
    }
```

Where `_build_graph_styles()` converts the YAML `graph_styles.node_types` into the `{nodeColors, nodeSizes, nodeIcons}` structure the frontend expects.

### 6.2 Frontend: fetch at startup

Replace the hardcoded `SCENARIO` export with a fetch from `/api/config/scenario`:

```typescript
// config.ts
export interface ScenarioConfig {
  name: string;
  displayName: string;
  description: string;
  graph: string;
  graphStyles: { nodeColors: Record<string, string>; nodeSizes: Record<string, number>; nodeIcons: Record<string, string> };
  exampleQuestions: string[];
  useCases: string[];
}

let _cached: ScenarioConfig | null = null;

export async function getScenario(): Promise<ScenarioConfig> {
  if (_cached) return _cached;
  const resp = await fetch("/api/config/scenario");
  _cached = await resp.json();
  return _cached!;
}

// Backward-compat: synchronous fallback for components that render before fetch completes
export const SCENARIO_DEFAULTS: ScenarioConfig = {
  name: "",
  displayName: "Loading...",
  description: "",
  graph: "",
  graphStyles: { nodeColors: {}, nodeSizes: {}, nodeIcons: {} },
  exampleQuestions: [],
  useCases: [],
};
```

### 6.3 Update components that reference `SCENARIO`

Search for all `import { SCENARIO }` in the frontend and update them to use the async `getScenario()` pattern. Typically this means:
- Lifting the fetch into a React context or top-level `useEffect`.
- Passing the resolved config via props or context.

This is the most frontend-heavy change. The scope is bounded because the current `SCENARIO` object is small and used in a handful of places.

---

## 7. Update `hooks/postprovision.sh`

| Line | Before | After |
|---|---|---|
| 25 | `DATA_DIR="$PROJECT_ROOT/data/scenarios/telco-noc/data/knowledge"` | `DATA_DIR="$PROJECT_ROOT/data/scenarios/${DEFAULT_SCENARIO}/data/knowledge"` |

`DEFAULT_SCENARIO` is available because we set it in azd env (step 1.4) and azd exports all env values to hooks.

---

## 8. Ensure `DEFAULT_SCENARIO` flows into the Container App

The Container App needs `DEFAULT_SCENARIO` as an env var so the runtime services (`api/` and `graph-query-api/`) know which scenario to load.

### 8.1 Bicep: add parameter

In `infra/main.bicep` (or `infra/app.bicep`), add:

```bicep
param defaultScenario string = ''
```

And pass it to the Container App environment variables:

```bicep
{
  name: 'DEFAULT_SCENARIO'
  value: defaultScenario
}
```

### 8.2 `azure.yaml`: wire the parameter

In `azure.yaml`, the `infra` section's `parameters` should include:

```yaml
infra:
  parameters:
    defaultScenario: ${AZURE_DEFAULT_SCENARIO}
```

Or more simply, use `azd env set` (already done in step 1.4) and read it in the Bicep via `readEnvironmentVariable()`.

---

## 9. Ensure `scenario.yaml` + scenario data get into the Docker image

The Dockerfile must COPY the data directory. Verify it already does:

```dockerfile
COPY data/ /app/data/
```

If not, add it. Since all scenarios live under `data/scenarios/`, no per-scenario Dockerfile changes are needed.

---

## 10. Scenario data directory: `generate_all.sh`

**File:** `data/scenarios/telco-noc/scripts/generate_all.sh`

| Lines | Before | After |
|---|---|---|
| 2, 5 | `"telco-noc"` references in comments | Update to generic text (cosmetic) |

This script generates data *for its own scenario* — the references are comments only. No functional change needed.

---

## 11. Execution Order

Implement in dependency order to keep the project deployable at every step:

| Phase | Steps | Description | Risk |
|---|---|---|---|
| **A** | 2 | Create `scenario_loader.py` | None — new file, nothing imports it yet |
| **B** | 3.1–3.7 | Update scripts to use `scenario_loader` | Low — scripts only run manually |
| **C** | 7 | Update `postprovision.sh` | Low — one-line change |
| **D** | 4.1–4.4 | Update `graph-query-api/config.py` + dependents | Medium — runtime service |
| **E** | 5.1–5.4 | Update `api/app/routers/config.py` | Medium — runtime service |
| **F** | 1.1–1.6 | Update `deploy.sh` | Low — orchestration only |
| **G** | 8 | Bicep: pass `DEFAULT_SCENARIO` to Container App | Low — infra parameter |
| **H** | 9 | Verify Dockerfile copies `data/` | Low — check only |
| **I** | 6.1–6.3 | Frontend: fetch scenario from API | Medium — requires API to be deployed |

### Suggested implementation order: A → B → C → F → G → H → D → E → I

This keeps the scripts and deployment working at every step. The runtime services (D, E) and frontend (I) are updated last because they require the env var / API to be in place.

---

## 12. Testing Checklist

After implementation, verify with the existing `telco-noc` scenario:

- [ ] `./deploy.sh --scenario telco-noc --provision-all --yes --skip-local` — full deployment works
- [ ] `./deploy.sh --provision-all --yes --skip-local` — auto-detects `telco-noc` (only scenario present)
- [ ] Agents are provisioned with correct prompt paths
- [ ] AI Search indexes are created with correct names from `scenario.yaml`
- [ ] Fabric resources (lakehouse, eventhouse, ontology) provision correctly
- [ ] Frontend loads scenario name, graph styles, and example questions from API
- [ ] `/api/config/current` returns correct graph name
- [ ] `/api/config/resources` returns correct resource graph
- [ ] `/query/health/sources` probes correct data sources
- [ ] `grep -rn "telco-noc" --include="*.py" --include="*.ts" --include="*.sh" api/ graph-query-api/ frontend/src/ scripts/ hooks/` returns **zero** results (only `data/scenarios/telco-noc/` should remain)

---

## 13. Files Changed — Summary

| File | Change Type | Complexity |
|---|---|---|
| `scripts/scenario_loader.py` | **New** | Low |
| `deploy.sh` | Edit — add `--scenario` flag + scenario validation | Low |
| `hooks/postprovision.sh` | Edit — parameterise path (1 line) | Trivial |
| `scripts/provision_search_index.py` | Edit — use `load_scenario()` for paths + index names | Low |
| `scripts/provision_cosmos.py` | Edit — use `load_scenario()` for data dir | Low |
| `scripts/provision_agents.py` | Edit — use `load_scenario()` for prompts dir + graph name | Low |
| `scripts/generate_topology_json.py` | Edit — default from env var | Trivial |
| `scripts/fabric/provision_lakehouse.py` | Edit — remove fallback default | Trivial |
| `scripts/fabric/provision_eventhouse.py` | Edit — remove fallback default | Trivial |
| `scripts/agent_provisioner.py` | Edit — update comments/docstrings | Trivial |
| `graph-query-api/config.py` | Edit — load from YAML instead of hardcoded | Medium |
| `graph-query-api/router_health.py` | Edit — use SCENARIO_NAME + DEFAULT_GRAPH from config | Low |
| `graph-query-api/search_indexer.py` | Edit — docstring only | Trivial |
| `graph-query-api/services/blob_uploader.py` | Edit — docstring only | Trivial |
| `api/app/routers/config.py` | Edit — replace hardcoded SCENARIO_CONFIG + add `/scenario` endpoint | Medium |
| `frontend/src/config.ts` | Edit — fetch from API instead of hardcoded | Medium |
| `infra/main.bicep` (or `app.bicep`) | Edit — add `defaultScenario` parameter | Low |
| `data/scenarios/telco-noc/scripts/generate_all.sh` | Edit — comments only | Trivial |

**Total: 1 new file, 17 edits (6 trivial, 7 low, 4 medium, 0 high)**
